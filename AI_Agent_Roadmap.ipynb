{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZQRSJT_y7uUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Dive into RAGs and AI Agents\n",
        "\n",
        " Basics of API Wrappers\n",
        "\n",
        "Use Case: Calling OpenAI API with wrapper."
      ],
      "metadata": {
        "id": "94JuRRW57vao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = 'your-api-key'\n",
        "response = openai.Completion.create(engine='davinci', prompt='Hello', max_tokens=5)"
      ],
      "metadata": {
        "id": "ho3M1N467xTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basics of Prompt Engineering\n",
        "\n",
        "Use Case: Chain of thought for math reasoning."
      ],
      "metadata": {
        "id": "blCyh1g573Dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Q: What is 5+3?\\nA: Let's think step-by-step. 5 plus 3 is 8. So the answer is 8.\""
      ],
      "metadata": {
        "id": "RN4D15cP74mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basics of LLMs\n",
        "\n",
        "Use Case: Understanding context window for summarization."
      ],
      "metadata": {
        "id": "7u0Z29Ko77-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Summarize the following text:\n",
        "[Insert long article here]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ch7-JaaO7-O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basics of RAGs\n",
        "\n",
        "Use Case: Retrieve relevant documents for answering questions."
      ],
      "metadata": {
        "id": "ErcVNN1l8ANQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "vectordb = FAISS.load_local(\"index\", OpenAIEmbeddings())\n",
        "docs = vectordb.similarity_search(\"What is contract law?\")"
      ],
      "metadata": {
        "id": "C96v282i8CnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basics of AI Agents\n",
        "\n",
        "Use Case: Autonomous tool-using agent."
      ],
      "metadata": {
        "id": "-o077bLk8Fin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "agent = initialize_agent(tools=[search_tool], llm=llm, agent_type=\"zero-shot-react-description\")\n",
        "response = agent.run(\"Search and summarize recent AI news\")"
      ],
      "metadata": {
        "id": "5ayuUcGU8JHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI Agent Frameworks\n",
        "\n",
        "Use Case: Plan + execute steps in multi-task problem."
      ],
      "metadata": {
        "id": "QP5QOMDh8RvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor\n",
        "# Define toolchain and memory, initialize executor with planning logic."
      ],
      "metadata": {
        "id": "veZ7VTVK8UXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Agent Systems\n",
        "\n",
        "Use Case: One agent summarizes, another translates."
      ],
      "metadata": {
        "id": "phM9JJYR8syH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = summarizer_agent.run(\"Summarize the article\")\n",
        "translation = translator_agent.run(f\"Translate to Spanish: {summary}\")"
      ],
      "metadata": {
        "id": "d0SCQvIJ8xkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation and Observability\n",
        "\n",
        "Use Case: Monitor latency and logs."
      ],
      "metadata": {
        "id": "I9IHzMes80gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "# call agent\n",
        "end = time.time()\n",
        "print(f\"Latency: {end - start}s\")"
      ],
      "metadata": {
        "id": "bHisPuPs84pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project for AI Assistant for Legal Queries\n",
        "\n",
        "This project integrates all concepts into one Python app using LangChain and OpenAI.\n",
        "\n",
        "\n",
        "This project includes:\n",
        "\n",
        "File/vector store usage (Python, RAGs)\n",
        "\n",
        "LLM calls (LLMs, API Wrappers)\n",
        "\n",
        "Prompt handling (Prompt Engineering)\n",
        "\n",
        "Agent planning and tool use (Agent Frameworks)\n",
        "\n",
        "Latency tracking (Evaluation)\n",
        "\n",
        "Modular structure for scaling to multi-agent"
      ],
      "metadata": {
        "id": "M7Y617pD9D5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import openai\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Config\n",
        "openai.api_key = 'your-api-key'\n",
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "# Step 1: Vector Store Setup (Basics of RAG)\n",
        "vector_store = FAISS.load_local(\"legal_index\", OpenAIEmbeddings())\n",
        "retriever = vector_store.as_retriever()\n",
        "qa_tool = RetrievalQA(llm=llm, retriever=retriever)\n",
        "\n",
        "# Step 2: Define Tools (Basics of AI Agents)\n",
        "tools = [\n",
        "    Tool(name=\"LegalRetriever\", func=qa_tool.run, description=\"Fetches legal documents to answer queries\")\n",
        "]\n",
        "\n",
        "# Step 3: Initialize Agent (Agent Framework)\n",
        "agent = initialize_agent(tools=tools, llm=llm, agent_type=\"zero-shot-react-description\")\n",
        "\n",
        "# Step 4: Evaluation and Observability\n",
        "query = \"What is the Fair Use doctrine?\"\n",
        "start_time = time.time()\n",
        "result = agent.run(query)\n",
        "end_time = time.time()\n",
        "\n",
        "# Step 5: Output\n",
        "print(\"\\nAnswer:\", result)\n",
        "print(\"Latency:\", end_time - start_time, \"seconds\")"
      ],
      "metadata": {
        "id": "BgSQ8OtC9OxW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}